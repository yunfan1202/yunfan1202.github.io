<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yunfan Ye's Homepage</title>

  <meta name="author" content="Yunfan Ye">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
      <style>
    .projects-box {
      /* background-color: green; */
      height: 160px;
      position: relative;
      overflow: hidden;
      transition: all ease-in .1s;

    }
    .projects-show {
      padding: 0;
      margin: 0;
      position: absolute;
      bottom: 0;
      left: 0;
      text-align: center;
      height: 30px;
      line-height: 20px;
      width: 100%;
      font-size: 12px;
      color: #0067c8;
      cursor: pointer;
      background: linear-gradient(to bottom, transparent, #fff, #fff);
    }
    .projects-show-text {
      position: relative;
      top: 10px;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yunfan Ye</name>
              </p>

              <p style="text-align:justify">Yunfan Ye (Âè∂‰∫ëÂ∏Ü) is an Assistant Professor in <a href="http://design.hnu.edu.cn/gy.htm">School of Design</a>, <a href="https://www.hnu.edu.cn/">Hunan University (HNU)</a>, China.
                I earned my Ph.D. degree in December 2023 in <a href="https://www.nudt.edu.cn/">National University of Defense Technology</a>, under the supervision of <a href="http://individual.utoronto.ca/zcai/">Prof. Zhiping Cai</a> and <a href="https://kevinkaixu.net/">Prof. Kai Xu</a> in <a href="https://kevinkaixu.net/group.html">iGrape Lab</a>.
                I got my Master's degree in Computer Science in 2019 from  <a href="https://www.stevens.edu/">Stevens Institute of Technology</a>, and Bachelor's degree in Computer Science in 2017 from <a href="https://www.xmu.edu.cn/">Xiamen University</a>, China.

              </p>

              <p style="text-align:center">
                <a href="mailto:yunfan1202@qq.com">Email</a> &nbsp/&nbsp
<!--                <a href="data/Yunfan-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/Yunfan-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=iTGg6eQAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/yunfan1202/">Github</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yeyunfan-photo.jpg"><img style="width:65%;max-width:65%" alt="profile photo" src="images/yeyunfan-photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

         <!--
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul class="projects-box" id="projects-box">
	      <li><b>[<font color="red">2024.01</font>]</b> One paper has been accepted by <em>IEEE TIP</em>.</li>

                  <p class="projects-show" id="projects-show"><span class="projects-show-text" id="projects-show-text">More</span></p>

              </ul>
            </td>
          </tr>
        </tbody></table>
        -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching</heading>
              <p>
                Intelligent Design Method (Êô∫ËÉΩËÆæËÆ°ÊñπÊ≥ï) <a href="https://github.com/yunfan1202/intellegent_design">[Code]</a>
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interest mainly include computer vision and graphics, intelligent design and their applications, especially edge detection, neural radiance field. The representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>

<!---------------------------------------------DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection------------------------------------------------------------------------------>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr bgcolor="#ffffd0">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/diffusion_edge.png' height= 90%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2401.02032.pdf">
                <papertitle>DiffusionEdge: Diffusion Probabilistic Model for Crisp Edge Detection</papertitle>
              </a>
              <br>
                <strong>Yunfan Ye*</strong>,
                <a href="https://kevinkaixu.net/">Kai Xu*</a>,
                <a href="https://github.com/GuHuangAI">Yuhang Huang‚Ä†</a>,
                <a href="https://renjiaoyi.github.io/">Renjiao Yi</a>,
                <a href="http://individual.utoronto.ca/zcai/">Zhiping Cai</a>
              <br>
              <em>AAAI</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2401.05975.pdf">[Paper]</a>
              <a href="https://github.com/GuHuangAI/DiffusionEdge">[Code]</a>
              <a href="https://mp.weixin.qq.com/s/rHMO1nFCvz44tLVcpDWOPw">[News]</a>
              <p></p>
              <p style="text-align:justify">
                Limited by the encoder-decoder architecture, learning-based edge detectors usually have difficulty predicting edge maps that satisfy both correctness and crispness. With the recent success of the diffusion probabilistic model (DPM), we found it is especially suitable for accurate and crisp edge detection...
              </p>
            </td>
          </tr>
<!---------------------------------------------NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-view Images------------------------------------------------------------------------------>
          <tr bgcolor="#ffffd0">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/NEF.png' width=112%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_NEF_Neural_Edge_Fields_for_3D_Parametric_Curve_Reconstruction_From_CVPR_2023_paper.pdf">
                <papertitle>NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-view Images</papertitle>
              </a>
              <br>
                <strong>Yunfan Ye</strong>,
                <a href="https://renjiaoyi.github.io/">Renjiao Yi</a>,
                <a href="https://github.com/zhirui-gao">Zhirui Gao</a>,
                <a href="https://www.zhuchenyang.net/">Chenyang Zhu</a>,
                <a href="http://individual.utoronto.ca/zcai/">Zhiping Cai</a>,
              <a href="https://kevinkaixu.net/">Kai Xu‚Ä†</a>
              <br>
              <em>CVPR</em>, 2023
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_NEF_Neural_Edge_Fields_for_3D_Parametric_Curve_Reconstruction_From_CVPR_2023_paper.pdf">[Paper]</a>
              <a href="https://github.com/yunfan1202/NEF_code">[Code]</a>
              <a href="https://yunfan1202.github.io/NEF/">[Project Page]</a>
              <p></p>
              <p style="text-align:justify">
                We study the problem of reconstructing 3D feature curves of an object from a set of calibrated multi-view images. To do so, we learn a neural implicit field representing the density distribution of 3D edges which we refer to as Neural Edge Field (NEF). Inspired by NeRF...
              </p>
            </td>
          </tr>
<!------------------------------------------------Delving into Crispness: Guided Label Refinement for Crisp Edge Detection--------------------------------------------------------------------------->
            <tr>
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/crisp_edge.png' width=115%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2306.15172.pdf">
                <papertitle>Delving into Crispness: Guided Label Refinement for Crisp Edge Detection</papertitle>
              </a>
              <br>
                <strong>Yunfan Ye</strong>,
                <a href="https://renjiaoyi.github.io/">Renjiao Yi</a>,
                <a href="https://github.com/zhirui-gao">Zhirui Gao</a>,
                <a href="http://individual.utoronto.ca/zcai/">Zhiping Cai‚Ä†</a>,
              <a href="https://kevinkaixu.net/">Kai Xu‚Ä†</a>
              <br>
              <em>IEEE TIP</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2306.15172.pdf">[Paper]</a>
              <a href="https://github.com/yunfan1202/Delving-into-Crispness">[Code]</a>

              <p></p>
              <p style="text-align:justify">
                Learning-based edge detection usually suffers from predicting thick edges. Through extensive quantitative study with a new edge crispness measure, we find that noisy human-labeled edges are the main cause of thick predictions...

              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->
<!--------------------------------------------------------------------------------------------------------------------------->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/STEdge.png' width=115%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2201.05121.pdf">
                <papertitle>STEdge: Self-Training Edge Detection With Multilayer Teaching and Regularization</papertitle>
              </a>
              <br>
                <strong>Yunfan Ye*</strong>,
                <a href="https://renjiaoyi.github.io/">Renjiao Yi*</a>,
                <a href="http://individual.utoronto.ca/zcai/">Zhiping Cai‚Ä†</a>,
              <a href="https://kevinkaixu.net/">Kai Xu‚Ä†</a>
              <br>
              <em>IEEE TNNLS</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2201.05121.pdf">[Paper]</a>
              <a href="https://github.com/yunfan1202/STEdge">[Code]</a>
              <p></p>
              <p style="text-align:justify">
                Learning-based edge detection has hereunto been strongly supervised with pixel-wise annotations which are tedious to obtain manually. We study the problem of self-training edge detection, leveraging the untapped wealth of large-scale unlabeled image datasets...
              </p>
            </td>
          </tr>

<!--------------------------------------------------------------------------------------------------------------------------->
<!--------------------------------------------------------------------------------------------------------------------------->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/watermarking.jpg' width=115%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10184464">
                <papertitle>Fixing the Double Agent Vulnerability of Deep Watermarking: A Patch-Level Solution against Artwork Plagiarism</papertitle>
              </a>
              <br>
                <a href="https://github.com/1024yy">Yuanjing Luo*</a>,
                <a href="https://tongqingzhou-nudt.github.io/">Tongqing Zhou*</a>,
                Shenglan Cui,
              <strong>Yunfan Ye</strong>,
              <a href="http://design.hnu.edu.cn/info/1023/5787.htm">Fang Liu‚Ä†</a>,
              Zhiping Cai
              <br>
              <em>IEEE TCSVT</em>, 2023
              <br>
              <a href="https://ieeexplore.ieee.org/document/10184464">[Paper]</a>
              <a href="https://github.com/1024yy/DIPW">[Code]</a>
              <p></p>
              <p style="text-align:justify">
Increasing artwork plagiarism incidents stresses the urgent need for proper copyright protection on behalf of the creators. The latest development in this context focuses on embedding watermarks via deep encoder-decoder networks...
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->
<!---------------------------------------------------------------------------------------------------------------------------><!--------------------------------------------------------------------------------------------------------------------------->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/template.jpg' width=115%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2303.08438.pdf">
                <papertitle>Learning Accurate Template Matching with Differentiable Coarse-to-Fine Correspondence Refinement</papertitle>
              </a>
              <br>
                <a href="https://github.com/zhirui-gao">Zhirui Gao</a>,
                <a href="https://renjiaoyi.github.io/">Renjiao Yi</a>,
                <a href="https://github.com/qinzheng93">Zheng Qin</a>,
                <strong>Yunfan Ye</strong>,
                <a href="https://www.zhuchenyang.net/">Chenyang Zhu</a>,
                <a href="https://kevinkaixu.net/">Kai Xu‚Ä†</a>
              <br>
              <br>
              <em>Computational Visual Media Journal (CVMJ)</em>
              <br>
              <a href="https://arxiv.org/pdf/2303.08438.pdf">[Paper]</a>
              <a href="https://github.com/zhirui-gao/Deep-Template-Matching">[Code]</a>
              <p></p>
              <p style="text-align:justify">
Template matching is a fundamental task in computer vision and has been studied for decades. It plays an essential role in manufacturing industry...
            </td>
          </tr>

<!--------------------------------------------------------------------------------------------------------------------------->

<!---------------------------------------------------------------------------------------------------------------------------><!--------------------------------------------------------------------------------------------------------------------------->
            <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/caption.jpg' width=115%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/article/10.1007/s00530-023-01178-8">
                <papertitle>Image Captioning for Cultural Artworks: a Case Study on Ceramics</papertitle>
              </a>
              <br>
              Baoying Zheng,
              <a href="http://design.hnu.edu.cn/info/1023/5787.htm">Fang Liu‚Ä†</a>,
              Mohan Zhang,
              <a href="https://tongqingzhou-nudt.github.io/">Tongqing Zhou</a>,
              Shenglan Cui,
              <strong>Yunfan Ye</strong>,
              Yeting Guo
              <br>
              <br>
              <em>Multimedia System</em>
              <br>
              <a href="https://link.springer.com/article/10.1007/s00530-023-01178-8">[Paper]</a>
              <p></p>
              <p style="text-align:justify">
                When viewing ancient artworks, people try to build connections with them to ‚Äòread‚Äô the correct messages from the past. A proper descriptive caption is essential for viewers...
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          </table>

        <p align="center">Source code from <a href="https://jonbarron.info/">Jon Barron</a>'s website</p>
        <script>
          let show = true;
          document.querySelector('#projects-show').onclick = function() {
            if (!show) {
              document.querySelector('#projects-box').style.height = 'auto';
              document.querySelector('#projects-box').style.paddingBottom = '20px';
              document.querySelector('#projects-show-text').innerHTML = 'Less';
              show = true;
            } else {
              show = false;
              document.querySelector('#projects-box').style.height = '160px';
              document.querySelector('#projects-box').style.paddingBottom = '0px';
              document.querySelector('#projects-show-text').innerHTML = 'More';
            }
          }
        </script>
</body>
</html>
